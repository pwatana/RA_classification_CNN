{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Optionally import seaborn for nicer plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you are in the project root or adjust path accordingly\n",
    "# from src.config_transfer import MODELS_DIR, HISTORY_NAME, MODEL_NAME\n",
    "# If not importing config_transfer, manually define paths:\n",
    "MODELS_DIR = 'models' # Or the full path if running from outside project root\n",
    "HISTORY_NAME = 'training_history_transfer.csv'\n",
    "MODEL_NAME = 'ra_classifier_transfer_cnn.h5' # For confusion matrix\n",
    "\n",
    "history_file_path = os.path.join(MODELS_DIR, HISTORY_NAME)\n",
    "model_file_path = os.path.join(MODELS_DIR, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training history from the CSV file\n",
    "history_df = pd.read_csv(history_file_path)\n",
    "print(history_df.head()) # See the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Precision and Recall\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history_df['precision'], label='Training Precision')\n",
    "plt.plot(history_df['recall'], label='Training Recall')\n",
    "plt.plot(history_df['val_precision'], label='Validation Precision')\n",
    "plt.plot(history_df['val_recall'], label='Validation Recall')\n",
    "plt.title('Precision & Recall over Epochs (for RA)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot AUC-ROC\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history_df['auc_roc'], label='Training AUC-ROC')\n",
    "plt.plot(history_df['val_auc_roc'], label='Validation AUC-ROC')\n",
    "plt.title('AUC-ROC over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() # Display the plots\n",
    "# plt.savefig(os.path.join(MODELS_DIR, 'training_curves.png')) # Save the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score\n",
    "import seaborn as sns # For heatmap\n",
    "\n",
    "# Assuming you have test_generator from a data_loader run\n",
    "# You might need to rerun data_loader_transfer.py to get test_generator\n",
    "# from src.data_loader_transfer import get_image_data_generators\n",
    "# _, _, test_generator = get_image_data_generators()\n",
    "\n",
    "# Load the best model\n",
    "# best_model = tf.keras.models.load_model(model_file_path)\n",
    "\n",
    "# Make predictions (y_pred_probs are probabilities from 0 to 1)\n",
    "# y_pred_probs = best_model.predict(test_generator)\n",
    "# y_pred_binary = (y_pred_probs > 0.5).astype(int) # Apply threshold\n",
    "\n",
    "# Get true labels (assuming test_generator.classes is available or you manually load labels)\n",
    "# test_generator.reset() # Reset if it's already been iterated\n",
    "# y_true = test_generator.classes\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "# cm = confusion_matrix(y_true, y_pred_binary)\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "#             xticklabels=['Healthy', 'RA'], yticklabels=['Healthy', 'RA'])\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.title('Confusion Matrix (Test Set)')\n",
    "# plt.show()\n",
    "\n",
    "# (You already calculate F1-Score and Specificity in train_transfer.py,\n",
    "# so you could just display those from the console output or store them in a summary file.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
